{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching SQL databases and analyzing results\n",
    "\n",
    "This notebook searches the created databases and analyses the results. The code here is written to work specifically for the cases presented in the publication. Only databases created with the datasets and code provided together with this notebook will generate the correct result. It would require  modification for the code to work with other datasets and databases.\n",
    "\n",
    "Rijksuniversiteit Groningen, 2018\n",
    "\n",
    "c.m.punter@rug.nl - Interfacing with postgreSQL, SQL translator, test, query, stats, conversion of query results, counting unique interactors and pairs, comments.\n",
    "\n",
    "\n",
    "w.m.smigiel@gmail.com - Counting interactions, checking GeneOntology, detailed statistics per unique interaction, exports, processing with pandas, plotting, comments, markdown, conversion to notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, connecting to postgreSQL and assigning variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# username, password and database as defined in the postgreSQL system\n",
    "\n",
    "username = 'postgres'\n",
    "password = 'password'\n",
    "database = 'intact_20201208'\n",
    "\n",
    "# connecting to the database\n",
    "\n",
    "conn = psycopg2.connect(\"user=%s password='%s' dbname='%s'\" % (username, password, database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO id's assigning a proteing to be located in the cytoplasm. Refer to http://geneontology.org/\n",
    "\n",
    "cytosol_goid = ['GO:0005737', 'GO:0005829']\n",
    "\n",
    "# relevant columns of the IntAct dataset\n",
    "\n",
    "columns = [\n",
    "    'interactor_a',\n",
    "    'interactor_b',\n",
    "    'alt_interactor_a',\n",
    "    'alt_interactor_b',\n",
    "    'alias_interactor_a',\n",
    "    'alias_interactor_b',\n",
    "    'detection_method',\n",
    "    'author',\n",
    "    'publication',\n",
    "    'taxonomy_a',\n",
    "    'taxonomy_b',\n",
    "    'interaction_type',\n",
    "    'source_database',\n",
    "    'interaction',\n",
    "    'confidence_score',\n",
    "    'xref_interactor_a',\n",
    "    'xref_interactor_b',\n",
    "]\n",
    "\n",
    "# all columns to be fetched from the SQL database\n",
    "\n",
    "all_columns = [\n",
    "    'interactor_a',\n",
    "    'interactor_b',\n",
    "    'alt_interactor_a',\n",
    "    'alt_interactor_b',\n",
    "    'alias_interactor_a',\n",
    "    'alias_interactor_b',\n",
    "    'detection_method',\n",
    "    'author',\n",
    "    'publication',\n",
    "    'taxonomy_a',\n",
    "    'taxonomy_b',\n",
    "    'interaction_type',\n",
    "    'source_database',\n",
    "    'interaction',\n",
    "    'confidence_score',\n",
    "    'xref_interactor_a',\n",
    "    'xref_interactor_b',\n",
    "\n",
    "    'sabu_Uniprot_a',\n",
    "    'sabu_Description_a',\n",
    "    'sabu_Gene_a',\n",
    "    'sabu_Peptides_a',\n",
    "    'sabu_Confidence_score_a',\n",
    "    'weight_a',\n",
    "    'sabu_Dataset_a',\n",
    "    'sabu_Glycerol_number_of_proteins_per_cell_a',\n",
    "    'sabu_Glycerol_fg_protein_per_cell_a',\n",
    "    'sabu_Glycerol_coeffcient_of_variance_a',\n",
    "    'sabu_Bnumber_a',\n",
    "    'sabu_Annotated_functional_COG_groups_a',\n",
    "    'sabu_Annotated_functional_COG_group_a',\n",
    "    'sabu_Annotated_functional_COG_class_a'\n",
    "\n",
    "    'sabu_Uniprot_b',\n",
    "    'sabu_Description_b',\n",
    "    'sabu_Gene_b',\n",
    "    'sabu_Peptides_b',\n",
    "    'sabu_Confidence_score_b',\n",
    "    'weight_b',\n",
    "    'sabu_Dataset_b',\n",
    "    'sabu_Glycerol_number_of_proteins_per_cell_b',\n",
    "    'sabu_Glycerol_fg_protein_per_cell_b',\n",
    "    'sabu_Glycerol_coeffcient_of_variance_b',\n",
    "    'sabu_Bnumber_b',\n",
    "    'sabu_Annotated_functional_COG_groups_b',\n",
    "    'sabu_Annotated_functional_COG_group_b',\n",
    "    'sabu_Annotated_functional_COG_class_b'\n",
    "]\n",
    "\n",
    "abundance_columns = [\n",
    "    'sabu_Uniprot',\n",
    "    'sabu_Description',\n",
    "    'sabu_Gene',\n",
    "    'sabu_Peptides',\n",
    "    'sabu_Confidence_score',\n",
    "    'weight',\n",
    "    'sabu_Dataset',\n",
    "    'sabu_Glycerol_number_of_proteins_per_cell',\n",
    "    'sabu_Glycerol_fg_protein_per_cell',\n",
    "    'sabu_Glycerol_coeffcient_of_variance',\n",
    "    'sabu_Bnumber',\n",
    "    'sabu_Annotated_functional_COG_groups',\n",
    "    'sabu_Annotated_functional_COG_group',\n",
    "    'sabu_Annotated_functional_COG_class'\n",
    "]\n",
    "\n",
    "# columns for pandas outputs\n",
    "\n",
    "columns_output = [\n",
    "    'unique_interactor',\n",
    "    'gene_name',\n",
    "    'interactions_other',\n",
    "    'interacions_self',\n",
    "    'interactions_all',\n",
    "    'abundance', \n",
    "    'MW',\n",
    "    'go_cytoplasm',\n",
    "    'membrane_in_go_all',\n",
    "    'periplasm_in_go_all',\n",
    "    'DNA_in_go_all',\n",
    "    'RNA_in_go_all',\n",
    "    'ribosome_in_go_all',\n",
    "    'has_pdb',\n",
    "    'go_all',\n",
    "    'sabu_group_letter',\n",
    "    'sabu_group_description',\n",
    "    'sabu_COG_class',\n",
    "    'unique_interactor',\n",
    "    'all_interactors_abundance',\n",
    "    'sum_abundance_inteactors'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to assign path to export files\n",
    "\n",
    "folder_file = lambda x: os.path.join(os.getcwd(), *x)\n",
    "\n",
    "# functions for more convenient SQL query syntax\n",
    "\n",
    "def sql_query(sql_select, sql_where):\n",
    "    sql_from = 'interactions inner join interaction_identifier on interactions.id = interaction_identifier.interaction_id '\n",
    "    sql_from += '\\n\\tinner join identifiers on interaction_identifier.identifier_id = identifiers.id '\n",
    "    sql_from += '\\n\\tleft outer join databases on identifiers.database_id = databases.id '\n",
    "    sql_from += '\\n\\tleft outer join abundance on identifiers.id = abundance.identifier_id'\n",
    "\n",
    "    return 'select %s\\nfrom %s\\nwhere %s\\n' % (', '.join(sql_select), sql_from, sql_combine('and', sql_where))\n",
    "\n",
    "\n",
    "def sql_combine(operator, *queries):\n",
    "    return '(%s)' % ((' %s\\n\\t' % operator).join(queries)) if queries else 'True'\n",
    "\n",
    "\n",
    "def sql_identifier(identifier, condition):\n",
    "    return \"type = '%s' and identifier %s\" % (identifier, condition)\n",
    "\n",
    "\n",
    "def sql_interactions(*conditions):\n",
    "    queries = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        queries.append(sql_query(['interactions.id'], condition))\n",
    "\n",
    "    sql_select = [\n",
    "        'interactions.id',\n",
    "        'confidence_score',\n",
    "        'type',\n",
    "        'name',\n",
    "        'identifier',\n",
    "        'ab',\n",
    "        'sabu_Uniprot',\n",
    "        'sabu_Description',\n",
    "        'sabu_Gene',\n",
    "        'sabu_Peptides',\n",
    "        'sabu_Confidence_score',\n",
    "        'weight',\n",
    "        'sabu_Dataset',\n",
    "        'sabu_Glycerol_number_of_proteins_per_cell',\n",
    "        'sabu_Glycerol_fg_protein_per_cell',\n",
    "        'sabu_Glycerol_coeffcient_of_variance',\n",
    "        'sabu_Bnumber',\n",
    "        'sabu_Annotated_functional_COG_groups',\n",
    "        'sabu_Annotated_functional_COG_group',\n",
    "        'sabu_Annotated_functional_COG_class'\n",
    "    ]\n",
    "\n",
    "    query = sql_query(sql_select, 'interactions.id in (\\n%s)' % 'intersect\\n'.join(queries))\n",
    "\n",
    "#     with open('query_sql.txt', 'wb') as f:\n",
    "#         f.write(query.encode('utf-8'))\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    interactions = cur.fetchall()\n",
    "    cur.close()\n",
    "\n",
    "    return interactions\n",
    "\n",
    "# converting the SQL search results to table format, MITAB 2.7-like\n",
    "\n",
    "def results_to_table(results):\n",
    "    interactions = {}\n",
    "\n",
    "    for id, confidence_score, type, database, identifier, ab, *abundance_values in results:\n",
    "\n",
    "        if id not in interactions:\n",
    "            interactions[id] = {}\n",
    "\n",
    "        if ab:\n",
    "            type = '%s_%s' % (type, ab)\n",
    "\n",
    "            for column, value in zip(abundance_columns, abundance_values):\n",
    "                if value:\n",
    "                    name = '%s_%s' % (column, ab)\n",
    "                    interactions[id][name] = [str(value)]\n",
    "\n",
    "        if type not in interactions[id]:\n",
    "            interactions[id][type] = []\n",
    "\n",
    "        interactions[id][type].append('%s:%s' % (database, identifier))\n",
    "\n",
    "    return interactions\n",
    "\n",
    "# converting the SQL search results to a more readable table format for export\n",
    "\n",
    "def results_to_csv(results, columns=all_columns, delimiter='\\t'):\n",
    "\n",
    "    interactions = {}\n",
    "\n",
    "    for id, confidence_score, type, database, identifier, ab, *abundance_values in results:\n",
    "        if id not in interactions:\n",
    "            interactions[id] = {}\n",
    "\n",
    "        if ab:\n",
    "            type = '%s_%s' % (type, ab)\n",
    "\n",
    "        if type not in interactions[id]:\n",
    "            interactions[id][type] = []\n",
    "\n",
    "        interactions[id][type].append('%s:%s' % (database, identifier))\n",
    "\n",
    "        if confidence_score:\n",
    "            interactions[id]['confidence_score'] = ['%f' % confidence_score]\n",
    "        else:\n",
    "            interactions[id]['confidence_score'] = ['']\n",
    "\n",
    "        for column, value in zip(abundance_columns, abundance_values):\n",
    "\n",
    "            if ab:\n",
    "\n",
    "                if value:\n",
    "                    name = '%s_%s' % (column, ab)\n",
    "                    interactions[id][name] = [str(value)]\n",
    "\n",
    "    rows = [columns]\n",
    "\n",
    "    for key in interactions.keys():\n",
    "        values = []\n",
    "        for column in columns:\n",
    "            if column not in interactions[key]:\n",
    "                values.append('')\n",
    "            else:\n",
    "                values.append('|'.join(interactions[key][column]))\n",
    "\n",
    "        rows.append(values)\n",
    "\n",
    "    return rows\n",
    "\n",
    "# testing database integrity\n",
    "\n",
    "def test_integrity():\n",
    "    # check if each line of abundance data is linked to a single protein\n",
    "    # the following query should be true\n",
    "    query = 'select count(distinct identifier_id) = count(identifier_id) '\n",
    "    query += 'from abundance '\n",
    "    query += 'where identifier_id is not NULL '\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()\n",
    "    if result[0] != True:\n",
    "        print('query was not True : ' + query)\n",
    "    else:\n",
    "        print('each abundance line is connected to a single protein ID - passed check query')\n",
    "    cur.close()\n",
    "\n",
    "    # check if all interactions have 2 different interactors\n",
    "    # and if each interactor has only one unique identifier (should be the case since we only use uniprot data)\n",
    "    # the max count returned should be 2!\n",
    "\n",
    "    query = 'select max(count) = 2 '\n",
    "    query += 'from ( '\n",
    "    query += 'select count(interaction_id) '\n",
    "    query += 'from interaction_identifier '\n",
    "    query += 'left join identifiers on interaction_identifier.identifier_id = identifiers.id '\n",
    "    query += \"where identifiers.type = 'interactor' \"\n",
    "    query += 'group by interaction_id '\n",
    "    query += 'order by count desc '\n",
    "    query += ') as counts '\n",
    "\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    result = cur.fetchone()\n",
    "    if result[0] != True:\n",
    "        print('query was not True : ' + query)\n",
    "    else:\n",
    "        print('passed check query')\n",
    "    cur.close()\n",
    "\n",
    "# counting unique abundances\n",
    "\n",
    "def count_uniques(results, *columns):\n",
    "    counts = dict()\n",
    "\n",
    "    for id, confidence_score, type, database, identifier, ab, *abundance_values in results:\n",
    "\n",
    "        all_values = dict(zip(abundance_columns, abundance_values))\n",
    "        all_values['id'] = id\n",
    "        all_values['ab'] = ab\n",
    "        all_values['database'] = database\n",
    "        all_values[type] = identifier\n",
    "\n",
    "        # check if all columns are present\n",
    "        if all(i in all_values for i in columns):\n",
    "            key = tuple([all_values[c] for c in columns])\n",
    "\n",
    "            if key in counts:\n",
    "                counts[key] += 1\n",
    "            else:\n",
    "                counts[key] = 1\n",
    "\n",
    "    return counts\n",
    "\n",
    "# function to generate short statics of the query results\n",
    "\n",
    "def generate_stats(table):\n",
    "\n",
    "    xx = list()\n",
    "    xy = list()\n",
    "    yx = list()\n",
    "    all = set()\n",
    "\n",
    "    for interaction in table.values():\n",
    "        interactor_a = interaction['interactor_a'][0]\n",
    "        interactor_b = interaction['interactor_b'][0]\n",
    "\n",
    "        # test and warning for interactors with multiple names\n",
    "        if len(interaction['interactor_a']) > 1 or len(interaction['interactor_b']) > 1:\n",
    "            print('warning; some interactors have multiple names')\n",
    "\n",
    "        interactors = (interactor_a, interactor_b)\n",
    "\n",
    "        if interactor_a == interactor_b:\n",
    "            xx.append(interactors)\n",
    "        else:\n",
    "            if (interactor_b, interactor_a) in xy:\n",
    "                yx.append((interactor_b, interactor_a))\n",
    "            else:\n",
    "                xy.append(interactors)\n",
    "\n",
    "        all.add(interactor_a)\n",
    "        all.add(interactor_b)\n",
    "\n",
    "    stats = [\n",
    "        ('interactor pairs (interactions)', (len(xx + xy + yx))),\n",
    "        ('unique interactor pairs (interactions)', (len(set(xx + xy + yx)))),\n",
    "        ('XX', len(xx)),\n",
    "        ('unique XX', len(set(xx))),\n",
    "        ('XY', len(xy)),\n",
    "        ('unique XY', len(set(xy))),\n",
    "        ('YX', len(yx)),\n",
    "        ('unique YX', len(set(yx))),\n",
    "        ('number of unique interactors', len(all))\n",
    "    ]\n",
    "    return stats\n",
    "\n",
    "# function to count unique interactors and generate a table\n",
    "\n",
    "def count_unique_interactors(table):\n",
    "\n",
    "    counts = []\n",
    "    all_unique_interactors = set()\n",
    "    for interaction in table.values():\n",
    "        interactor_a = interaction['interactor_a'][0]\n",
    "        interactor_b = interaction['interactor_b'][0]\n",
    "        all_unique_interactors.add(interactor_a)\n",
    "        all_unique_interactors.add(interactor_b)\n",
    "\n",
    "    for interactor in all_unique_interactors:\n",
    "        all = 0\n",
    "        in_x = 0\n",
    "        in_y = 0\n",
    "        in_xx = 0\n",
    "\n",
    "        for interaction in table.values():\n",
    "            interactor_a = interaction['interactor_a'][0]\n",
    "            interactor_b = interaction['interactor_b'][0]\n",
    "\n",
    "            if interactor_a == interactor:\n",
    "                in_x += 1\n",
    "            elif interactor_b == interactor:\n",
    "                in_y += 1\n",
    "\n",
    "            if interactor_a == interactor or interactor_b == interactor:\n",
    "                all += 1\n",
    "\n",
    "                if interactor_a == interactor_b:\n",
    "                    in_xx += 1\n",
    "\n",
    "        counts.append((interactor, all, in_x, in_y, in_xx))\n",
    "    return counts\n",
    "\n",
    "# function to retrieve and count all unique protein pairs\n",
    "\n",
    "def get_combinations(table):\n",
    "\n",
    "    all_proteins_combinations = dict()\n",
    "\n",
    "    for interaction in table.values():\n",
    "        interactor_a = interaction['interactor_a'][0]\n",
    "        interactor_b = interaction['interactor_b'][0]\n",
    "        xy = (interactor_a, interactor_b)\n",
    "        yx = (interactor_b, interactor_a)\n",
    "\n",
    "        if xy in all_proteins_combinations:\n",
    "            all_proteins_combinations[xy] += 1\n",
    "        elif yx in all_proteins_combinations:\n",
    "            all_proteins_combinations[yx] += 1\n",
    "        else:\n",
    "            all_proteins_combinations[xy] = 1\n",
    "    return all_proteins_combinations\n",
    "\n",
    "# function that counts number of all interactions, self-interactions, particular GO annotations.\n",
    "\n",
    "def process_table(table, all_unique_interactors, all_proteins_combinations, cytosol_goid): \n",
    "\n",
    "    all_unique_interactors_list = list(all_unique_interactors)\n",
    "    key_list = list(all_proteins_combinations.keys())\n",
    "    interactor_unique_interaction_count = []\n",
    "\n",
    "    for unique_interactor in all_unique_interactors_list:\n",
    "        unique_interactor = unique_interactor[0]\n",
    "\n",
    "        counter = 0\n",
    "        selfint = 0\n",
    "        counter_all = 0\n",
    "\n",
    "        for pair in key_list:\n",
    "\n",
    "            if unique_interactor == pair[0] and unique_interactor != pair[1]:\n",
    "                counter += 1\n",
    "            elif unique_interactor == pair[1] and unique_interactor != pair[0]:\n",
    "                counter += 1\n",
    "            elif unique_interactor == pair[1] and pair[1] == pair[0]:\n",
    "                selfint += 1\n",
    "\n",
    "        counter_all = counter + selfint\n",
    "\n",
    "        go_list_cyt = []\n",
    "        go_list_all = []\n",
    "\n",
    "        for interaction in table.values():\n",
    "            \n",
    "            pdb = 0\n",
    "            abundance = 0\n",
    "            name = ''\n",
    "            weight = ''\n",
    "            letter = ''\n",
    "            group = ''\n",
    "            sabuclass = ''\n",
    "            membrane = 0\n",
    "            periplasm = 0\n",
    "            rna = 0\n",
    "            dna = 0\n",
    "            ribosome = 0\n",
    "\n",
    "            if unique_interactor == interaction['interactor_a'][0]:\n",
    "\n",
    "                for xref in interaction['xref_interactor_a']:\n",
    "\n",
    "                    if 'pdb' in xref:\n",
    "                        pdb = 1\n",
    "\n",
    "                    if 'go:' in xref:\n",
    "                        go_list_all.append(xref)\n",
    "\n",
    "                    for id in cytosol_goid:\n",
    "\n",
    "                        if id in xref:\n",
    "                            go_list_cyt.append(xref)\n",
    "\n",
    "                if 'sabu_Glycerol_number_of_proteins_per_cell_a' in interaction:\n",
    "                    abundance = interaction['sabu_Glycerol_number_of_proteins_per_cell_a'][0]\n",
    "                    name = interaction['sabu_Gene_a'][0]\n",
    "                    weight = interaction['weight_a'][0]\n",
    "\n",
    "                if 'sabu_Annotated_functional_COG_group_a' in interaction:\n",
    "\n",
    "                    letter = interaction['sabu_Annotated_functional_COG_groups_a'][0]\n",
    "                    group = interaction['sabu_Annotated_functional_COG_group_a'][0]\n",
    "                    sabuclass = interaction['sabu_Annotated_functional_COG_class_a'][0]\n",
    "\n",
    "                    \n",
    "                break\n",
    "\n",
    "            elif unique_interactor == interaction['interactor_b'][0]:\n",
    "                for xref in interaction['xref_interactor_b']:\n",
    "\n",
    "                    if 'pdb' in xref:\n",
    "                        pdb = 1\n",
    "\n",
    "                    if 'go:' in xref:\n",
    "                        go_list_all.append(xref)\n",
    "\n",
    "                    for id in cytosol_goid:\n",
    "\n",
    "                        if id in xref:\n",
    "                            go_list_cyt.append(xref)\n",
    "\n",
    "                if 'sabu_Glycerol_number_of_proteins_per_cell_b' in interaction:\n",
    "                    abundance = interaction['sabu_Glycerol_number_of_proteins_per_cell_b'][0]\n",
    "                    name = interaction['sabu_Gene_b'][0]\n",
    "                    weight = interaction['weight_b'][0]\n",
    "\n",
    "                if 'sabu_Annotated_functional_COG_group_b' in interaction:\n",
    "                    letter = interaction['sabu_Annotated_functional_COG_groups_b'][0]\n",
    "                    group = interaction['sabu_Annotated_functional_COG_group_b'][0]\n",
    "                    sabuclass = interaction['sabu_Annotated_functional_COG_class_b'][0]\n",
    "\n",
    "                break\n",
    "\n",
    "        if not go_list_all:\n",
    "            go_set_all = ''\n",
    "        else:\n",
    "            if any('MEMBRANE' in go.upper() for go in go_list_all):\n",
    "                membrane = 1\n",
    "\n",
    "            if any('PERIPLASM' in go.upper() for go in go_list_all):\n",
    "                periplasm = 1\n",
    "\n",
    "            if any('RNA' in go.upper() for go in go_list_all):\n",
    "                rna = 1\n",
    "\n",
    "            if any('DNA' in go.upper() for go in go_list_all):\n",
    "                dna = 1\n",
    "\n",
    "            if any('RIBOSOM' in go.upper() for go in go_list_all):\n",
    "                ribosome = 1\n",
    "\n",
    "            go_set_all = set(go_list_all)\n",
    "        go_str_all = '|'.join(go_set_all)\n",
    "\n",
    "        if not go_list_cyt:\n",
    "            go_set = ''\n",
    "        else:\n",
    "            go_set = set(go_list_cyt)\n",
    "        go_str = '|'.join(go_set)\n",
    "\n",
    "        interactor_unique_interaction_count.append((unique_interactor, name, counter, selfint, counter_all, abundance, weight, go_str, membrane, periplasm, dna, rna, ribosome, pdb, go_str_all, letter,  group, sabuclass))\n",
    "        \n",
    "    return interactor_unique_interaction_count\n",
    "\n",
    "# this function returns sum of abuntances of all interacting partners\n",
    "\n",
    "def sum_partners(all_unique_interactors, all_proteins_combinations, interactor_unique_interaction_count):\n",
    "    \n",
    "    all_unique_interactors_list = list(all_unique_interactors)\n",
    "    key_list = list(all_proteins_combinations.keys())\n",
    "    interactor_unique_interaction_sums = []\n",
    "\n",
    "    for interactor in all_unique_interactors_list:\n",
    "        interactor = interactor[0]\n",
    "\n",
    "        partners_abu = []\n",
    "        partners = []\n",
    "\n",
    "        for pair in key_list:\n",
    "\n",
    "            if interactor == pair[0] and interactor != pair[1]:\n",
    "                for line in interactor_unique_interaction_count:\n",
    "\n",
    "                    if pair[1] == line[0]:\n",
    "                        \n",
    "                        if line[5] != '':\n",
    "                            partners_abu.append(int(line[5]))\n",
    "                        else:\n",
    "                            partners_abu.append(float('nan'))\n",
    "                            \n",
    "                        tu_part = '%s:%s' % (line[0], line[5])\n",
    "                        partners.append(tu_part)\n",
    "\n",
    "            if interactor == pair[1] and interactor != pair[0]:           \n",
    "                for line in interactor_unique_interaction_count:\n",
    "\n",
    "                    if pair[0] == line[0]:\n",
    "                        \n",
    "                        if line[5] != '':\n",
    "                            partners_abu.append(int(line[5]))\n",
    "                        else:\n",
    "                            partners_abu.append(float('nan'))\n",
    "                            \n",
    "                        tu_part = '%s:%s' % (line[0], line[5])\n",
    "                        partners.append(tu_part)\n",
    "\n",
    "        sum_partners_abu = sum(list(partners_abu))\n",
    "        s_partners = ';'.join(partners)\n",
    "\n",
    "        interactor_unique_interaction_sums.append((interactor, s_partners, sum_partners_abu))\n",
    "        \n",
    "    return interactor_unique_interaction_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the database integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "each abundance line is connected to a single protein ID - passed check query\n",
      "passed check query\n"
     ]
    }
   ],
   "source": [
    "test_integrity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving proteins with abundance above 1000 copies/cell\n",
    "\n",
    "Here we filter the  data for all _E. coli_ proteins with abundance above 1000 copies per cell. \n",
    "\n",
    "The database is taken from Schmidt et al. 2015, supporting informations. We manually transfered relevant columns from the provided .xlsx file to a text-based table. \n",
    "\n",
    "See the publication text for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Schmidt et al. database\n",
    "\n",
    "sabu = pd.read_table('sabu.txt')\n",
    "\n",
    "# changing column names to fit the output from the SQL queries\n",
    "\n",
    "sabu_columns = [\n",
    "    'sabu_Uniprot Accession',\n",
    "    'sabu_Gene',\n",
    "    'sabu_Molecular weight (Da)',\n",
    "    'sabu_Glycerol_number_of_proteins_per_cell',\n",
    "    'sabu_Annotated functional COG groups (letter)',\n",
    "    'sabu_Annotated functional COG group (description)',\n",
    "    'sabu_Annotated functional COG class'\n",
    "]\n",
    "\n",
    "out_columns = [\n",
    "    'unique_interactor',\n",
    "    'gene_name',\n",
    "    'MW',\n",
    "    'abundance', \n",
    "    'sabu_group_letter',\n",
    "    'sabu_group_description',\n",
    "    'sabu_COG_class'\n",
    "]\n",
    "\n",
    "sabu = sabu.rename(columns=dict(zip(sabu_columns, out_columns)))\n",
    "\n",
    "# get all uniprot id's of proteins with abundance above 1000 copies/cell\n",
    "    \n",
    "sabu_above_1000 = sabu.loc[sabu['abundance'] >= 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query - interactions of proteins above 1000 copies/cell\n",
    "\n",
    "Here we are interested in retreiving interactome data for all _E. coli_ proteins with abundance above 1000 copies per cell. The list of UniProt ID's of such proteins was retrieved in the section above. We iterate through the list, and we search the postgreSQL databases in search of all of the interactions of the protein of interest.\n",
    "\n",
    "The query takes data from entries that:\n",
    "* have both interactors tagged with _E. coli_ taxonomy ID\n",
    "* are described by interaction type physical interaction\n",
    "* at least one of the interactor's UniProt ID matches with the one of the protein of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def individual_protein_query(uid):\n",
    "    \n",
    "    results = sql_interactions(\n",
    "       sql_combine('or',\n",
    "           sql_combine('and', sql_identifier('taxonomy', \"like '%83333%'\"), \"ab = 'a'\"),\n",
    "           sql_combine('and', sql_identifier('taxonomy', \"like '%83333%'\"), \"ab = 'b'\"),\n",
    "       ),\n",
    "       sql_combine('or',\n",
    "            sql_identifier('interaction_type', \"like '%0914%'\"),\n",
    "            sql_identifier('interaction_type', \"like '%0915%'\")\n",
    "        ),\n",
    "        sql_combine('or',\n",
    "            sql_combine('and', sql_identifier('interactor', f\"like '{uid}'\"), \"ab = 'a'\"),\n",
    "            sql_combine('and', sql_identifier('interactor', f\"like '{uid}'\"), \"ab = 'b'\"),\n",
    "        ),\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# creating empty dataframes for outputs\n",
    "\n",
    "out = pd.DataFrame([])\n",
    "no_interactions = pd.DataFrame([])  \n",
    "\n",
    "counter = 0\n",
    "total_searches = len(sabu_above_1000['unique_interactor'])\n",
    "\n",
    "for uid, name in list(zip(sabu_above_1000['unique_interactor'], sabu_above_1000['gene_name'])):\n",
    "    \n",
    "    counter += 1\n",
    "    \n",
    "    print(uid, name, f'{counter} done out of {total_searches}', end='\\r')\n",
    "    \n",
    "    # create a folder for each protein individually\n",
    "    \n",
    "    os.makedirs(folder_file(('individual_protein_results', name)), exist_ok=True)\n",
    "    \n",
    "    # for a short description of what the functions are doing refer to the section above.\n",
    "    \n",
    "    results = individual_protein_query(uid)\n",
    "    table = results_to_table(results)\n",
    "    csv_output = results_to_csv(results)\n",
    "    stats = generate_stats(table)\n",
    "    all_unique_interactors = count_unique_interactors(table)\n",
    "    all_proteins_combinations = get_combinations(table)\n",
    "    interactor_unique_interaction_count = process_table(table, all_unique_interactors, all_proteins_combinations, cytosol_goid)\n",
    "    interactor_unique_interaction_sums = sum_partners(all_unique_interactors, all_proteins_combinations, interactor_unique_interaction_count)\n",
    "    \n",
    "    # outputs of the 'process_table' and 'sum_partners' functions are merged into a complete table\n",
    "    \n",
    "    df_interactor_unique_interaction_count = pd.DataFrame(interactor_unique_interaction_count,\n",
    "                 columns=columns_output[:-3]\n",
    "                )\n",
    "\n",
    "    df_interactor_unique_interaction_sums = pd.DataFrame(interactor_unique_interaction_sums, \n",
    "                 columns=columns_output[-3:]\n",
    "                )\n",
    "\n",
    "    merged_interactor_unique_interaction = df_interactor_unique_interaction_count.merge(\n",
    "        df_interactor_unique_interaction_sums,\n",
    "        left_on='unique_interactor', right_on='unique_interactor'\n",
    "    )\n",
    "    \n",
    "    # calculating loneliness = abundance of a protein divided by \n",
    "    # the sum of abundances of all it's interactors\n",
    "\n",
    "    merged_interactor_unique_interaction['loneliness'] = merged_interactor_unique_interaction['abundance'].astype(float) / merged_interactor_unique_interaction['sum_abundance_inteactors']\n",
    "    \n",
    "    # appending line of the search protein to output\n",
    "    # depending on whether any interactions were found\n",
    "    \n",
    "    try:\n",
    "        out = pd.concat([out, merged_interactor_unique_interaction.loc[merged_interactor_unique_interaction['unique_interactor'].str.split(':', n=1, expand=True)[1] == uid]])\n",
    "    except KeyError:\n",
    "        no_interactions = pd.concat([no_interactions, sabu_above_1000.loc[sabu_above_1000['unique_interactor'] == uid]])\n",
    "        \n",
    "        print(uid, name, 'no interactions found.')\n",
    "    \n",
    "    # export to csv - intermediate search steps for each protein\n",
    "    \n",
    "    pd.DataFrame(csv_output[1:],columns=csv_output[0]).to_csv(folder_file(('individual_protein_results', name, f'{name}_query_results.csv')))\n",
    "    \n",
    "    pd.DataFrame(stats).to_csv(folder_file(('individual_protein_results', name, f'{name}_query_results_statistics.csv')))\n",
    "    \n",
    "    pd.DataFrame([(*ids, number) for ids, number in zip(all_proteins_combinations.keys(), all_proteins_combinations.values())]).to_csv(\n",
    "        folder_file(('individual_protein_results', name, f'{name}_unique_protein_pairs.csv')))\n",
    "    \n",
    "    merged_interactor_unique_interaction.to_csv(folder_file(('individual_protein_results', name, f'{name}_unique_interactions_per_protein_loneliness_q.csv')))\n",
    "    \n",
    "# export to csv - data of proteins with abundance above 1000 without any interactions found\n",
    "\n",
    "no_interactions.to_csv('no_interactions_found.csv')\n",
    "\n",
    "# calculating quantiles of selected columns\n",
    "# this creates easy to asses, sortable columns, where outlayers and average proteins\n",
    "# can be easily selected\n",
    "\n",
    "out['MW_decile'] = pd.qcut(out['MW'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "out['interactions_other_quintile'] = pd.qcut(out['interactions_other'], 5, labels=range(1,6))\n",
    "\n",
    "out['abundance_decile'] = pd.qcut(out['abundance'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "out['loneliness_decile'] = pd.qcut(out['loneliness'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "# export to csv - data of proteins with abundance above 1000 with interactions found\n",
    "\n",
    "out.sort_values('loneliness').to_csv('interactions_found.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually selected data\n",
    "\n",
    "Based on the abundance, molecular weight and loneliness quantiles we manually picked a set of proteins that represent extreme and average cases. We produced a set of proteins varied in terms of all those parameters. Additinally we checked for availability of the C-terminus for tagging based on available structures, available knock-outs and the oligomeric state.\n",
    "\n",
    "Note that _ppc_, _aceB_, _sucC_ and were excluded form the experimental analysis.\n",
    "* _ppc_ failed to produce an expressing clone.\n",
    "* _aceB_ C-terminus is used for activity. We attemped to tag the N-terminus of the protein, yet that failed to produce an expressing clone.\n",
    "* _sucC_ forms a heterotetrameric complex with it's interactor, _sucD_. A dual-expression system would be required for this protein exist close to it's native state. That would create a significant difference in the cell state between this protein and others, so we decided not to include it in the study.\n",
    "\n",
    "We were unable to acquire data for the following proteins due to aggregation:\n",
    "* _metK_\n",
    "\n",
    "For more details, see the publication text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the third position in each tuple is the oligomeric state of the product of each gene\n",
    "# as followed from UniProt\n",
    "# 2.5 for sucC is put in as a placeholder for displaying on a graph\n",
    "# sucC is heterodimeric with sucD\n",
    "\n",
    "manually_picked_proteins = [\n",
    "    ('P0A9G6', 'aceA', 4),\n",
    "    ('P00934', 'thrC', 1),\n",
    "    ('P18843', 'nadE', 2),\n",
    "    ('P0A836', 'sucC', 2.5),\n",
    "    ('P0A9K9', 'slyD', 1),\n",
    "    ('P0C0L2', 'osmC', 2),\n",
    "    ('P0AC62', 'grxC', 1),\n",
    "    ('P05793', 'ilvC', 4),\n",
    "    ('P00864', 'ppc', 4),\n",
    "    ('P08997', 'aceB', 1),\n",
    "    ('P0A6A8', 'acpP', 1),\n",
    "    ('P0ACC3', 'erpA', 2),\n",
    "    ('P0A763', 'ndk', 4),\n",
    "    ('P0AA25', 'trxA', 1),\n",
    "    ('P07813', 'leuS', 1),\n",
    "    ('P30125', 'leuB', 2),\n",
    "    ('P0A817', 'metK', 4),\n",
    "    ('P08200', 'icd', 2)\n",
    "]\n",
    "\n",
    "manually_picked_proteins = pd.DataFrame(manually_picked_proteins)\n",
    "\n",
    "# creating indicators for proteins that weren't measured with microscopy\n",
    "\n",
    "no_expression = ['sucC', 'ppc', 'aceB']\n",
    "\n",
    "aggregating = ['metK']\n",
    "\n",
    "# selecting out the manually picked proteins\n",
    "\n",
    "picked_out = out.loc[out['unique_interactor'].str.split(':', n=1, expand=True)[1].isin(manually_picked_proteins[0])]\n",
    "\n",
    "# adding oligomeric state data\n",
    "\n",
    "picked_out = picked_out.merge( manually_picked_proteins[[1, 2]], left_on='gene_name', right_on=1).rename(columns={2 : 'oligomeric_state'}).drop(1, axis=1)\n",
    "\n",
    "# creating aggregation/failure to express columns\n",
    "\n",
    "picked_out['has_construct'] = 0\n",
    "picked_out.loc[~picked_out['gene_name'].isin(no_expression), 'has_construct'] = 1\n",
    "\n",
    "picked_out['aggregates'] = 0\n",
    "picked_out.loc[~picked_out['gene_name'].isin(aggregating), 'aggregates'] = 1\n",
    "\n",
    "\n",
    "# export to csv - data of manually picked proteins\n",
    "\n",
    "picked_out.to_csv('manually_selected.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P0ADB7 ecnB no interactions found.\n",
      "P0AF96 tabA no interactions found.\n",
      "P09169 ompT no interactions found.\n",
      "P0AAX6 mcbA no interactions found.\n",
      "P63224 gmhA no interactions found.\n",
      "P16700 cysP 261 done out of 2359\r"
     ]
    }
   ],
   "source": [
    "def all_proteins_query(uid_all):\n",
    "    \n",
    "    results_all = sql_interactions(\n",
    "       sql_combine('or',\n",
    "           sql_combine('and', sql_identifier('taxonomy', \"like '%83333%'\"), \"ab = 'a'\"),\n",
    "           sql_combine('and', sql_identifier('taxonomy', \"like '%83333%'\"), \"ab = 'b'\"),\n",
    "       ),\n",
    "       sql_combine('or',\n",
    "            sql_identifier('interaction_type', \"like '%0914%'\"),\n",
    "            sql_identifier('interaction_type', \"like '%0915%'\")\n",
    "        ),\n",
    "        sql_combine('or',\n",
    "            sql_combine('and', sql_identifier('interactor', f\"like '{uid_all}'\"), \"ab = 'a'\"),\n",
    "            sql_combine('and', sql_identifier('interactor', f\"like '{uid_all}'\"), \"ab = 'b'\"),\n",
    "        ),\n",
    "    )\n",
    "    return results_all\n",
    "\n",
    "# creating empty dataframes for outputs\n",
    "\n",
    "out_all = pd.DataFrame([])\n",
    "no_interactions_all = pd.DataFrame([])  \n",
    "\n",
    "\n",
    "total_searches_all = len(sabu)\n",
    "\n",
    "for i in sabu.index:\n",
    "        \n",
    "    uid_all, name_all = sabu.loc[i, ['unique_interactor', 'gene_name']]\n",
    "\n",
    "    if type(name_all) == float:\n",
    "        name_all = uid_all\n",
    "\n",
    "    # create a folder for each protein individually\n",
    "\n",
    "    os.makedirs(folder_file(('all_proteins_results', f'{i}_{name_all}')), exist_ok=True)\n",
    "\n",
    "    # for a short description of what the functions are doing refer to the section above.\n",
    "\n",
    "    results_all = all_proteins_query(uid_all)\n",
    "    table_all = results_to_table(results_all)\n",
    "    csv_output_all = results_to_csv(results_all)\n",
    "    stats_all = generate_stats(table_all)\n",
    "    all_unique_interactors_all = count_unique_interactors(table_all)\n",
    "    all_proteins_combinations_all = get_combinations(table_all)\n",
    "    interactor_unique_interaction_count_all = process_table(table_all, all_unique_interactors_all, all_proteins_combinations_all, cytosol_goid)\n",
    "    interactor_unique_interaction_sums_all = sum_partners(all_unique_interactors_all, all_proteins_combinations_all, interactor_unique_interaction_count_all)\n",
    "\n",
    "    # outputs of the 'process_table' and 'sum_partners' functions are merged into a complete table\n",
    "\n",
    "    df_interactor_unique_interaction_count_all = pd.DataFrame(interactor_unique_interaction_count_all,\n",
    "                 columns=columns_output[:-3]\n",
    "                )\n",
    "\n",
    "    df_interactor_unique_interaction_sums_all = pd.DataFrame(interactor_unique_interaction_sums_all, \n",
    "                 columns=columns_output[-3:]\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "    interactor_unique_interaction_count_all = df_interactor_unique_interaction_count_all.merge(\n",
    "        df_interactor_unique_interaction_sums_all,\n",
    "        left_on='unique_interactor', right_on='unique_interactor'\n",
    "    )\n",
    "\n",
    "    # calculating loneliness = abundance of a protein divided by \n",
    "    # the sum of abundances of all it's interactors\n",
    "\n",
    "    interactor_unique_interaction_count_all['loneliness'] = interactor_unique_interaction_count_all['abundance'].astype(float) / interactor_unique_interaction_count_all['sum_abundance_inteactors']\n",
    "\n",
    "    # appending line of the search protein to output\n",
    "    # depending on whether any interactions were found\n",
    "\n",
    "    try:\n",
    "        out_all = pd.concat([out_all, interactor_unique_interaction_count_all.loc[interactor_unique_interaction_count_all['unique_interactor'].str.split(':', n=1, expand=True)[1] == uid_all]])\n",
    "    except KeyError:\n",
    "        no_interactions_all = pd.concat([no_interactions_all, sabu_above_1000.loc[sabu_above_1000['unique_interactor'] == uid_all]])\n",
    "\n",
    "        print(uid_all, name_all, 'no interactions found.')\n",
    "\n",
    "    # export to csv - intermediate search steps for each protein\n",
    "\n",
    "    pd.DataFrame(csv_output_all[1:],columns=csv_output_all[0]).to_csv(folder_file(('all_proteins_results', f'{i}_{name_all}', f'{name_all}_query_results.csv')))\n",
    "\n",
    "    pd.DataFrame(stats_all).to_csv(folder_file(('all_proteins_results', f'{i}_{name_all}', f'{name_all}_query_results_statistics.csv')))\n",
    "\n",
    "    pd.DataFrame([(*ids, number) for ids, number in zip(all_proteins_combinations_all.keys(), all_proteins_combinations_all.values())]).to_csv(\n",
    "        folder_file(('all_proteins_results', f'{i}_{name_all}', f'{name_all}_unique_protein_pairs.csv')))\n",
    "\n",
    "    interactor_unique_interaction_count_all.to_csv(folder_file(('all_proteins_results', f'{i}_{name_all}', f'{name_all}_unique_interactions_per_protein_loneliness_q.csv')))\n",
    "    \n",
    "    print(uid_all, name_all, f'{i + 1} done out of {total_searches_all}', end='\\r')\n",
    "    \n",
    "# export to csv - data of proteins with abundance above 1000 without any interactions found\n",
    "\n",
    "no_interactions_all.to_csv('no_interactions_found_all.csv')\n",
    "\n",
    "# calculating quantiles of selected columns\n",
    "# this creates easy to asses, sortable columns, where outlayers and average proteins\n",
    "# can be easily selected\n",
    "\n",
    "out_all['MW_decile'] = pd.qcut(out_all['MW'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "out_all['interactions_other_quintile'] = pd.qcut(out_all['interactions_other'], 5, labels=range(1,6))\n",
    "\n",
    "out_all['abundance_decile'] = pd.qcut(out_all['abundance'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "out_all['loneliness_decile'] = pd.qcut(out_all['loneliness'].astype(float), 10, labels=range(1, 11))\n",
    "\n",
    "# export to csv - data of proteins with abundance above 1000 with interactions found\n",
    "\n",
    "out_all.sort_values('loneliness').to_csv('interactions_found_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
